{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Guitar App Data Updater",
   "metadata": {
    "cell_id": "709bd6f5-4fa7-4eba-94b7-9b7db4439c4e",
    "tags": [],
    "is_collapsed": false,
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<h3> This notebook will do the following:</h3>\n<ul>\n    <li>Import the exsisting master data from AWS S3 using boto 3</li>\n    <li>Import the new data from webscrape from AWS S3 using boto 3 </li>\n    <li>Clean and prepare new data for modeling using Pandas, RE, AST (Abstract Syntax Trees)</li>\n    <li>Merge the old data with the new data and upload to AWS S3 using boto 3</li>\n    <li>Build and save new model using new master data as pkl file and upload to AWS S3 using boto 3 </li>\n</ul>",
   "metadata": {
    "cell_id": "221c68f3-07ef-47ec-a957-1f8de4d4705c",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "cell_id": "001dec9d-f20a-4783-88de-c6e27db03f80",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "1b6af578-8548-4b51-b04d-c934f3778780",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9b3c0e72",
    "execution_start": 1645468148888,
    "execution_millis": 1,
    "deepnote_cell_height": 225,
    "deepnote_cell_type": "code"
   },
   "source": "## import required files for connecting to AWS\nimport pandas as pd\nimport re\nimport ast\nimport configparser\n\nimport logging\nimport boto3\nimport boto3.session\nfrom botocore.exceptions import ClientError\nimport os\n\nimport pickle\n\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Set AWS credentials from secret file\nconfig = configparser.ConfigParser()\nconfig.read('aws.ini')\n    \nAWS_key_id     = config['aws']['aws_access_key_id']\nAWS_secret_key = config['aws']['aws_secret_access_key']   \n    \n\n# Creating the low level functional client\nclient = boto3.client(\n    's3',\n    aws_access_key_id = AWS_key_id,\n    aws_secret_access_key =  AWS_secret_key,\n    region_name = 'us-east-1'\n)\n    \n# Creating the high level object oriented interface\nresource = boto3.resource(\n    's3',\n    aws_access_key_id = AWS_key_id,\n    aws_secret_access_key =  AWS_secret_key,\n    region_name = 'us-east-1'\n)",
   "metadata": {
    "cell_id": "24d880e5-8fb6-48c9-9bb9-8c91b8afe24a",
    "tags": [],
    "deepnote_cell_height": 459,
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c836f6b2",
    "execution_start": 1645467559486,
    "execution_millis": 1089,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# sanity check, see if the bucket can be accessed\nclientResponse = client.list_buckets()\n    \n# Print the bucket names one by one\nprint('Getting bucket name..')\nfor bucket in clientResponse['Buckets']:\n    print(f'Bucket Name: {bucket[\"Name\"]}')",
   "metadata": {
    "cell_id": "30bffbf2-602f-492f-915d-8e671ef2b38e",
    "tags": [],
    "deepnote_cell_height": 240.375,
    "deepnote_to_be_reexecuted": false,
    "source_hash": "85f5918",
    "execution_start": 1645468154660,
    "execution_millis": 99,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Getting bucket name..\nBucket Name: dataforguitarapp\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<b name='import'>Check if the existing model can be pulled from AWS</b>",
   "metadata": {
    "cell_id": "24357018-1439-45e6-8649-2455850267ee",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "# reading in pickle data \n\nresponse = client.get_object(Bucket='dataforguitarapp', Key='guitar.pkl')\n\nbody = response['Body'].read()\ndatamodel = pickle.loads(body)\n\n# verify that the file is an LR model\ntype(datamodel)",
   "metadata": {
    "cell_id": "55e25725-25b9-4ff4-bfb4-5a2df926fc48",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6634509d",
    "execution_start": 1645468319407,
    "execution_millis": 72,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 12,
     "data": {
      "text/plain": "sklearn.linear_model._base.LinearRegression"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<b>Get the existing master data which will be merged with the newly scraped data. </b>",
   "metadata": {
    "cell_id": "c68c301b-6e5b-4705-996c-21e76344f9bc",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "\n# Create the S3 object\nobj = client.get_object(\n    Bucket = 'dataforguitarapp',\n    Key = 'full_data.csv'\n)\n    \n# Read data from the S3 object\nmain_df = pd.read_csv(obj['Body'])\n\n    \n# inspect the data frame\nmain_df.info()",
   "metadata": {
    "cell_id": "4646e281-927d-4f9f-8dde-4721c8034fba",
    "tags": [],
    "deepnote_cell_height": 835.0625,
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bf8801db",
    "execution_start": 1645460562875,
    "execution_millis": 1632,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 112938 entries, 0 to 112937\nData columns (total 20 columns):\n #   Column          Non-Null Count   Dtype \n---  ------          --------------   ----- \n 0   Unnamed: 0      112938 non-null  int64 \n 1   title           112938 non-null  object\n 2   brand           112938 non-null  object\n 3   condition       112938 non-null  object\n 4   categories      112938 non-null  object\n 5   price           112938 non-null  object\n 6   pickups         112938 non-null  object\n 7   type            112938 non-null  object\n 8   model           112938 non-null  object\n 9   finish          111638 non-null  object\n 10  origin          112938 non-null  object\n 11  year            112938 non-null  object\n 12  top             112938 non-null  object\n 13  handed          112938 non-null  object\n 14  neck            112938 non-null  object\n 15  product_group   112938 non-null  object\n 16  body_type       112938 non-null  object\n 17  body_material   112938 non-null  object\n 18  frets           112938 non-null  int64 \n 19  available_sale  112938 non-null  int64 \ndtypes: int64(3), object(17)\nmemory usage: 17.2+ MB\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<b>Get the newly webscraped data</b>",
   "metadata": {
    "cell_id": "3ad61d4e-88d4-45f0-9043-24f40d9f52ed",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "# Create the S3 object\nobj2 = client.get_object(\n    Bucket = 'dataforguitarapp',\n    Key = 'update_data.csv'\n)\n    \n# Read data from the S3 object\nupdate_df = pd.read_csv(obj2['Body'])\n\n    \n# inspect the data frame\nupdate_df.info()",
   "metadata": {
    "cell_id": "9a7f173b-84d2-441f-b5ab-d6c15dbb59ff",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<b>Clean the new data and prep for modeling</b>",
   "metadata": {
    "cell_id": "47596337-2186-4eb2-ba09-d76ae04224bf",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport ast\nimport re\n\nfrom tqdm import tqdm\ntqdm.pandas()\n\n\n\ndef clean_year(txt):\n    txt = txt.replace(\"'59\",'1959').replace(\"'60\",'1960').replace(\"'61\",'1961').replace(\"'62\",'1962')\n    txt = txt.replace(\"'70s\",'1970s')\\\n            .replace(\"'60s\",'1960s')\\\n            .replace(\"'80s\",'1980s')\\\n            .replace(\"'90s\",'1990s')\\\n            .replace(\"'00s\",'2000s')\\\n            .replace(\"'00s\",'2000s')\n    return txt\n\n\ndef expand_data(df):\n    df = df[df.more_info.notnull()] # make sure there are no NaN in the more_info column\n    \n    project_data = df.copy().reset_index()\n    dropped_count = 0 # counter to report if any records were dropped \n    \n    expanded_project_data = pd.DataFrame()\n    \n    for val in tqdm(project_data.more_info):\n        #print(val.index)\n        val = val.replace('\"',\"'\")\n        val = clean_year(val)\n        \n        #line = re.sub(r\"'\\d\\d\", \"\", val)\n        try:\n            val = ast.literal_eval(val)\n            more_df = pd.DataFrame([val])    \n        \n            #result = pd.concat([sampledata, more_df], axis=1, join='inner')\n            expanded_project_data = expanded_project_data.append(more_df)\n        except:\n            dropped_count += 1\n            #print('dropped record')\n    print(f'There were {dropped_count} records that could not  be processed')\n    return expanded_project_data\n\ndef clean_price(txt):\n    '''\n    function to remove $ from price and replace commas then convert to float \n    '''        \n    txt = txt.replace('$','')\n    txt = txt.replace(',','')\n    #txt = \"{:.2f}\".format(float(txt))\n    #txt = float(txt)\n    return float(txt)\n\n\ndef encode_price(df):\n    conditions = [df.price < 500,\n                  df.price < 1000,\n                  df.price < 1500,\n                  df.price < 2500,\n                  df.price < 3500\n                 ]\n    \n    values = [0,1,2,3,4]\n    df['price_code'] = np.select(conditions, values, default=6)\n\n\n# feature origin code\ndef clean_origin(df):    \n    ## Correcting origin for American Made guitars\n    \n    df['origin'].loc[(df['model'].str.contains('American')) & (df['origin'] == 'Asia')] = 'United States'\n    \n    \n    ## Correcting origin for Ibanez guitars\n    df['origin'].loc[(df['origin']=='Asia') & \n                                     (df['model'].str.contains('AG')) &\n                                     (df['brand']=='Ibanez')] = 'Japan'\n    \n    df['origin'].loc[(df['origin']=='Asia') & \n                                     (df['model'].str.contains('RG')) &\n                                     (df['brand']=='Ibanez')] = 'Japan'\n    \n    df['origin'].loc[(df['origin']=='Asia') & \n                                     (df['model'].str.contains('RX')) &\n                                     (df['brand']=='Ibanez')] = 'Japan'\n    \n    df['origin'].loc[(df['origin']=='Asia') & \n                                     (df['model'].str.contains('Prestige')) &\n                                     (df['brand']=='Ibanez')] = 'Japan'\n    \n    df['origin'].loc[(df['origin']=='Asia') & \n                                     (df['model'].str.contains('Signature')) &\n                                     (df['brand']=='Ibanez')] = 'Japan'\n    \n    df['origin'].loc[(df['origin']=='Asia') & \n                                     (df['model'].str.contains('Artcore')) &\n                                     (df['brand']=='Ibanez')] = 'Korea'\n    \ndef extract_origin(df):\n    origin_dict = {\n        'Asia':0,\n        'China':0,\n        'Russia':0,\n        'Vietnam':0,\n        'ChinaIndonesia':1,\n        'Indonesia':1,\n        'Vietnam':1,\n        'Germany':2,\n        'Korea':2,\n        'Mexico':3,\n        'Japan':3,\n        'United States':4,\n    }\n    df['origin_code'] = (\n        df.origin\n          .str.extract('(' + '|'.join(origin_dict.keys()) + ')')\n          .squeeze().map(origin_dict)\n    )\n    \n    \n    \n    \ndef encode_type(df):\n    conditions = [df.type=='Solid Body',\n                  df.type=='Semi-Hollow',\n                  df.type=='Hollow Body',\n                  df.type=='Other'\n                 ]\n    \n    values = [3,2,1,0]\n    df['type_code'] = np.select(conditions, values)\n\n# encode Condition\ndef reduce_condition(df):\n    conditions = [df.condition.str.contains('Mint'), \n                  df.condition.str.contains('Excellent'),\n                  df.condition.str.contains('Very Good'),\n                  df.condition.str.contains('Good'),\n                  df.condition.str.contains('Fair'),\n                  df.condition.str.contains('Poor')\n                 ]\n    \n    values = ['Mint','Excellent','Very Good','Good','Fair','Poor']\n    df['condition'] = np.select(conditions, values)\n    \ndef encode_condition(df):\n    conditions = [df.condition.str.contains('Mint'), \n                  df.condition.str.contains('Excellent'),\n                  df.condition.str.contains('Very Good'),\n                  df.condition.str.contains('Good'),\n                  df.condition.str.contains('Fair'),\n                  df.condition.str.contains('Poor')\n                 ]\n    \n    values = [5,4,3,2,1,0]\n    df['cond_score'] = np.select(conditions, values, default=3)\n\n\n# cleaning up types to prep for encoding body type\ndef clean_type(df): \n    ## cleaning up PRS types\n    df['type'].loc[(df.type=='unknown') &\n                            (df.brand=='PRS')]='PRS style'\n    \n    df['type'].loc[(df.type=='unknown') &\n                            (df.title.str.contains('Silver Sky'))]='Stratocaster'\n    \n    #df_under10k['type'].loc[(df_under10k.type=='unknown') &\n    #                        (df_under10k.title.str.contains('McCarty'))]='PRS style'\n    \n    \n    ## capturing all Fender types\n    df['type'].loc[(df.type=='unknown') &\n                            (df.title.str.contains('Stratocaster'))]='Stratocaster'\n    \n    df['type'].loc[(df.type=='unknown') &\n    df(df.title.str.contains('Tele'))]='Telecaster'\n    \n    df['type'].loc[(df.type=='unknown') &\n                            (df.title.str.contains('Strat'))]='Stratocaster'\n    \n    df['type'].loc[(df.type=='unknown') &\n                            (df.title.str.contains('Jazzmaster'))]='Jazzmaster'\n    \n    df['type'].loc[(df.type=='unknown') &\n                            (df.title.str.contains('Jaguar'))]='Jaguar'\n    \n    ## capturing all ibanez types\n    df['type'].loc[(df.type=='unknown') &\n                            (df.title.str.contains('Ibanez'))]='Stratocaster'\n    #df_under10k['type'].loc[(df_under10k.type=='unknown') &\n    #                        (df_under10k.title.str.contains('Statocaster'))]='Strat'\n    \n    ## capturing all Gibson types\n    df['type'].loc[(df.type=='unknown') &\n                            (df.title.str.contains('Les Paul'))]='Les Paul'\n    \n    df['type'].loc[(df.type=='unknown') &\n                            (df.title.str.contains('SG'))]='SG'\n    \n    df['type'].loc[(df.type=='unknown') &\n                            (df.title.str.contains('Flying'))]='Flying V'\n    \n    df['type'].loc[(df.type=='unknown') &\n                            (df.title.str.contains('ES'))]='ES'\n    \n    df['type'].loc[(df.type=='unknown') &\n                            (df.title.str.contains('Casino'))]='ES'\n    \n    df['type'].loc[(df.type=='unknown') &\n                        (df.title.str.contains('Sheraton'))]='ES'\n\n# feature engineer body_code \ndef reduce_types(df): \n    body_dict = {\n                'unknown':0,     \n                'Stratocaster':4,\n                'ES':4,          \n                'PRS style':2,   \n                'Telecaster':5,  \n                'Les Paul':6,    \n                'SG':3,          \n                'Jazzmaster':1,  \n                'Coronado':1,    \n                'Mustang':1,           \n                'Esquire':2,           \n                'Cyclone':2,\n                    }\n    df['body_code'] = (\n        df.type\n          .str.extract('(' + '|'.join(body_dict.keys()) + ')')\n          .squeeze().map(body_dict)\n    )\n    \n    \ndef clean_raw_data(df):\n    '''\n    This function will clean and prepare the webscraped data for modeling\n    input: webscraped data as df\n    output: clean, model-ready data\n    '''\n    # copy df first\n    model_df = df.copy()\n    expand(model_df)\n    \n    # remove data with no price\n    model_df = model_df[model_df.price!='unknown']\n    \n    # Clean price \n    model_df['price'] = model_df['price'].progress_apply(clean_price)\n    \n    # limit data to >300 and <10000\n    model_df = model_df[model_df.price < 10000]\n    model_df = model_df[model_df.price > 300]\n    \n    # encode price\n    encode_price(model_df)\n    \n    \n    # extract origin and drop nulls\n    clean_corigin(model_df)\n    extract_origin(model_df)\n    model_df = model_df[model_df['origin_code'].notna()]\n    \n    # reduce and encode condition\n    reduce_condition(model_df)\n    encode_condition(model_df)\n    \n    # clean up types\n    clean_type(model_df)\n    \n    # reduce and encode type\n    reduce_types(model_df)\n    \n    return model_df\n    ",
   "metadata": {
    "cell_id": "917c84c6-dd41-46dc-a155-e034aac14446",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "clean_updated_df = clean_raw_data(update_df)",
   "metadata": {
    "cell_id": "f82d52de-7d7a-4a13-b9ac-042bace48fdb",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<b>Combine the old and new data</b>",
   "metadata": {
    "cell_id": "f2ac2450-0d25-480c-953f-df9128af51eb",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "new_model_df = pd.concat([main_df,clean_updated_df])",
   "metadata": {
    "cell_id": "7a9f3733-99e6-4c71-8431-12020b3461c3",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<b>Create the new model and save pkl file</b>",
   "metadata": {
    "cell_id": "f4d69d9c-12f2-4696-882e-7c9ccf75cad7",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "def runModel_compare(df,features_in):\n    X = df[features_in] \n    Y = df['price']\n\n    #from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=101)\n\n    #from sklearn.linear_model import LinearRegression\n    model = LinearRegression()\n    model.fit(X_train,y_train)\n\n    # print the intercept\n    # print(model.intercept_)\n\n    coeff_parameter = pd.DataFrame(model.coef_,X.columns,columns=['Coefficient'])\n    #coeff_parameter\n\n    predictions = model.predict(X_test)\n    #predictions\n\n    ## plotting the data\n    #sns.regplot(x='X-Axis', y='Y-Axis', data=df, scatter_kws={\"color\": \"red\"}, line_kws={\"color\": \"green\"})\n    p = sns.regplot(y_test,predictions,scatter_kws={\"color\": \"blue\"}, line_kws={\"color\": \"red\"}).set(title=f'Model using {features_in}')\n\n    plt.xlabel(\"Guitar Prices\")\n    plt.ylabel(f'Features')\n    \n\n    #from sklearn.metrics import mean_squared_error\n    #import math\n\n    actual = y_test\n    predicted = predictions\n\n    mse = mean_squared_error(actual, predicted)\n    rmse = math.sqrt(mse)\n\n    model.fit(X_train,y_train)\n    \n    print('--- Scores: ---')\n    print(f'Model Score: {model.score(X_train,y_train)}')\n    print(f'MSE: {mse} \\nRMSE: {rmse}')\n    \n    X_train_Sm= sm.add_constant(X_train)\n    X_train_Sm= sm.add_constant(X_train)\n    ls=sm.GLS(y_train,X_train_Sm).fit()\n    print(f'Adj. R-Squared: {ls.rsquared_adj}')\n    print(f'R-Squared: {ls.rsquared}')\n    #print(f'Mean Squared Error: {ls.mse_model}')\n    print(f'Log-likelihood: {ls.llf}')    \n    print('')\n    print('--- Comparison ---')\n    #manually test accuracy\n    df_results = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n    #df_results['accuracy'] = df_results.Predicted / df_results.Actual if (df_results.Predicted / df_results.Actual)<1.0 else \n    df_comparison = pd.merge(df_results,modeling_data, how=\"inner\", left_on=\"Actual\", right_on=\"price\")\n    #df_comparison.columns\n\n    pred_df = df_comparison[['title',\n                   'Predicted', \n                   'Actual',\n                   'brand',\n                   'origin',\n                   'condition']]\n    pd.options.display.float_format = '{:,.2f}'.format\n    compare_vals = pred_df[pred_df.Actual<5000].value_counts().head(20)\n    print(compare_vals)\n    print('--- Regression Plot --- ')\n    \n    # save the model to disk\n    # create an iterator object with write permission - model.pkl\n    with open('guitar.pkl', 'wb') as files:\n        pickle.dump(model, files)",
   "metadata": {
    "cell_id": "7993d948-4475-44f7-b3b4-fd3db6447438",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "## set which features will go into model\nfeatures_in = ['type_code','origin_code','cond_score','body_code','price_code']\n\n## create the model with the new data\nrunModel_compare(new_model_df,features_in)",
   "metadata": {
    "cell_id": "b991cb11-331f-4d98-ad21-fb4a018b0b8c",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<b>Replace old model in AWS with new model using new data </b>",
   "metadata": {
    "cell_id": "df79726e-485c-40d4-93e1-91c11b6e0327",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "#Creating Session With Boto3.\nsession = boto3.Session(\naws_access_key_id = AWS_key_id,\naws_secret_access_key =  AWS_secret_key,\nregion_name = 'us-east-1'\n)\n\n#Creating S3 Resource From the Session.\n#s3 = session.resource('s3')\n\n#txt_data = b'This is the content of the file uploaded from python boto3 asdfasdf'\n\n#object = s3.Object('dataforguitarapp', '../models/guitar.pkl')\n\n#result = object.put(Body=txt_data)\n\n\n\n\ns3_resource = session.resource('s3')\n\nbucket='dataforguitarapp'\nkey= 'guitar.pkl'\n\npickle_byte_obj = pickle.dumps(model)\n\ns3_resource.Object(bucket,key).put(Body=pickle_byte_obj)",
   "metadata": {
    "cell_id": "d924d805-9938-421a-b908-3b87e1f3642c",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<b>Replace old master data with new master data using combined data </b>",
   "metadata": {
    "cell_id": "bd3dbfa9-47ec-421c-9d83-ce198d334142",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "# code here",
   "metadata": {
    "cell_id": "dd5a9159-d9ac-4f1b-8fac-7b3abcf7d6a0",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "cell_id": "dd7d2e7e-2504-4c0b-8f91-15e7b9863f8d",
    "tags": [],
    "deepnote_cell_height": 306.1875,
    "deepnote_to_be_reexecuted": false,
    "source_hash": "38700176",
    "execution_start": 1645460595469,
    "execution_millis": 1471,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# ",
   "metadata": {
    "cell_id": "26b2dc81-734d-42fa-ab24-0064066c9eee",
    "tags": [],
    "is_collapsed": false,
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "cell_id": "aa215cb6-75f7-43b4-a24c-69fad365c069",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b623e53d",
    "deepnote_cell_height": 118.1875,
    "execution_start": 1645468496016,
    "execution_millis": 1,
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "cell_id": "c3f4754e-5e67-4445-b8e3-e3db27c4792d",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=110fa109-4784-4901-832e-96131bae9e6e' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "64bfc6d7-4a8c-4d0e-b6c4-4f06630820b7",
  "deepnote_execution_queue": []
 }
}